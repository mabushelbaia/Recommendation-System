\chapter{Experiment And Results}
\minitoc

\section{Dataset}

The dataset used in this experiment is called AliCPP and it is a public dataset that contains user-item interactions from an e-commerce platform. The dataset gather traffic logs of recommendation systems in Taobao, a Chinese online shopping website. The dataset is collected from the real-world recommendation system of Taobao.\cite{AliCPP}


\section{Experimental Setup}

In order to evaluate the performance of the proposed solution with real-world data, the environment has to be accelerated with a GPU.

\subsection{Hardware Environment}

To achieve this, the experiment is conducted on a cloud-based environment, specifically on an AWS EC2 p3.2xlarge instance \cite{AwsEc2P3}.

The instance is equipped with 8 vCPUs, 61 GiB of memory, and a single NVIDIA Tesla V100 GPU.

The V100 is a high-end GPU that is designed for AI workloads especially deep learning tasks.
It is based on the Volta architecture and is equipped with 5120 CUDA cores, 640 Tensor cores, and 32GB of HBM2 memory with 1.1 TB/s.
It can deliver 7 TFLOPS of double-precision floating-point performance and 116 TFLOPS of deep learning performance.

Figure \ref{fig:V100vsCPU} shows the performance comparison between the Tesla V100 and a CPU.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/v100-vs-cpu.png}
    \caption[Tesla V100 vs CPU]{Tesla V100 vs CPU \cite{NvidiaV100DataSheet}}
    \label{fig:V100vsCPU}
\end{figure}

\subsection{Software Environment}

In addition to the hardware environment, the software environment is also important to be considered.
Having access to \textbf{Nvidia Inception Program} \cite{NvidiaStartups}, 
which includes access to NVIDIA AI Enterprise \cite{NvidiaAiEnterprise} with \textbf{Nvidia GPU Cloud (NGC) Catalog}\cite{NvidiaNGC}.

Instead of setting up the drivers, tools, libraries and frameworks manually, 
the Nvidia AI Enterprise provides a pre-configured flavor of Linux Ubuntu that includes all necessities for deep learning tasks.

In addition to that, instead of compiling the Merlin TensorFlow from the source code, 
the Nvidia Merlin TensorFlow Container \cite{NvidiaMerlinTf} was used as a runtime for the experiment Jupyter notebook.



\section{Evaluation Results}
The evaluation of the proposed solution is conducted using the AliCPP dataset using different models like MLP, DLRM, DCN, and Wide\&Deep with an evaluation metric of AUC, Furthermore, we studied the effect of the number of epochs on the training and validation loss and AUC using BCE as a loss function.

\subsection{AUC Comparison}

The Area Under the Curve (AUC) metric describes a model's ability to separate positive and negative instances. A higher AUC indicates stronger distinction between the two classes. Where the AUC value ranges from 0 to 1, where 0.5 is the random guess and 1 is the perfect model.

The AUC metric is used to evaluate the performance of the models on the AliCPP dataset. The results are shown in Figure \ref{fig:AUCComparison}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/models_comparasion.png}
    \caption[AUC Comparison]{AUC Comparison}
    \label{fig:AUCComparison}
\end{figure}

The results show that all the models had a similar performance with AUC values around 0.5, which indicates that the models are not able to distinguish between positive and negative instances.

\subsection{Training and Validation}
We studied the effect of the number of epochs on the training and validation loss using BCE as a loss function. The results are shown in Figure \ref{fig:LossComparison}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/loss_epochs_20.png}
    \caption[Loss Comparison]{Loss Comparison}
    \label{fig:LossComparison}
\end{figure}

The results show that the training loss decreases as the number of epochs increases, while the validation loss increases as the number of epochs increases. This indicates that the model is overfitting the training data and is not able to generalize well to the validation data. Furthermore, by plotting the AUC score over the number of epochs, we can confirm that the model has overfitted the training data as shown in Figure \ref{fig:AUCOverEpochs}, where the AUC score for the training data increases as the number of epochs increases, while the AUC score for the validation data is constant around 0.5.


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/auc_epochs_20.png}
    \caption[AUC Over Epochs]{AUC Over Epochs}
    \label{fig:AUCOverEpochs}
\end{figure}

