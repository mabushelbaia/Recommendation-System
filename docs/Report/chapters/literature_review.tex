\chapter{Literature Review}
\minitoc

\section{Functional Requirements}

The system should provide a RESTful API as the final interface to be used by the front-end application.
The API provides endpoints that allow inserting customers, products, and interactions. It also provides endpoints for retrieving the recommendations for a given customer.

\section{System Requirements}

In order to for the system to be useful it has to meet the following specifications:

\subsection{Scalability}
Scalability implies that it has to be cloud-native, the inference system should apply proper load balancing across multi-node, multi model deployments.

\subsection{Real-time predictions}
To be usable in any website or application, the system should be able to provide real-time predictions, suggestions, with few milliseconds latency. \\

To fulfil this requirement, trained models should run on optimized inference servers or services, the suggested deployment plan is to use
\textbf{Nvidia Triton}
\footnote{Nvidia Triton Inference Server, part of the Nvidia AI platform and available with Nvidia AI Enterprise, is open-source software that standardizes AI model deployment and execution across every workload.}
inference server \cite{Triton}, 
integrated with \textbf{Amazon SageMaker} model deployment\cite{SageMaker} as infrastructure.

\subsection{Near Real-time Training}

This implies continuous training and deployment of model which requires the automation of training and deployment.

\subsection{Elasticity \& Optimization}

Elasticity is vital for keeping up with traffic spikes and declines while optimizing infrastructure costs. To achieve this, the system should be able to scale up and down based on the traffic and load.

\subsection{Security}

Like any other system, the system has to be immune to security threats by implementing best practices at every level in the deployment and design. \\ \\
\textit{e.g} rate-limiting requests to interaction injection endpoints, using attestation when possible, limiting access to user and product CRUD operations.

\section{Related Work}

There are many open-source and paid solutions that provide recommendation systems and libraries, this section discusses some of them.

\subsection{LightFM  }
is a Python library that implements a variety of recommendation algorithms, including collaborative filtering, content-based filtering, and hybrid methods. It is easy to use and produces high-quality results.


TODO

\section{Related Paid Solutions}

TODO