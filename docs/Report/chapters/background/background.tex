\chapter{Background}
\minitoc

\section{Recommendation Systems}\label{sec:recommendation-systems}
A recommendation system is an artificial intelligence or AI algorithm, usually associated with ML, that uses Big Data to suggest or recommend additional products to consumers. These can be based on various criteria, including past purchases, search history, demographic information, and other factors~\cite{NvidiaRecSys}. \\ \\
Recommender systems undergo training to understand the preferences, earlier decisions, and attributes of the user and products using their past interactions which include impressions, clicks, purchases, and ratings. Recommender systems are usually used by content and product providers to suggest items to users that they may like based on their profiles and preferences. 

\section{Types of Recommendation Systems}\label{sec:types-of-recommendation-systems}

\subsection{Context Filtering}
Context Filtering is a technique that uses the contextual information of the user by framing the recommendation problem as a contextual multi-armed bandit problem and using the contextual information to learn the user's preferences as shown in Figure \ref{fig:Context-Filtering-Diagram}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/contextual-sequence-prediction.png}
    \caption[Context Filtering Diagram]{Context Filtering Diagram~\cite{NvidiaRecSys}} 
    \label{fig:Context-Filtering-Diagram}
\end{figure}

\subsection{Collaborative Filtering}
A technique that filters out products that a customer might like based on reactions by similar users. It functions by clustering customers into smaller sets with similar interests. Then it uses the items they show interest in to create a ranked suggestions list. The idea behind this technique is that individuals who have previously agreed will continue to do so in the future. The figure \ref{fig:collaborative-filtering} shows a diagram of the collaborative filtering technique.

\subsection{Content Filtering}
A technique that uses the features of items a user has interacted with to recommend more items with similar features. This technique is based on the idea that if a customer shows interest in a particular product, he will also be interested in a similar product with similar features. The figure \ref{fig:content-filtering} shows a diagram of the content filtering technique. \\



\begin{figure}[H]
    \centering
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=0.8\linewidth]{assets/content_based_filtering.png}
        \caption{Content Filtering}
        \label{fig:content-filtering}
    \end{subfigure}%
    \begin{subfigure}{.5\textwidth}
        \centering
        \includegraphics[width=0.95\linewidth]{assets/collaborative_filtering.png}
        \caption{Collaborative Filtering Diagram}
        \label{fig:collaborative-filtering}
    \end{subfigure}
    \caption[Nvidia Glossary Diagram]{Nvidia Glossary Diagram~\cite{NvidiaRecSys}}
\end{figure}


\subsection{Hybrid Recommendation Systems}
Combine the advantages of multiple types of recommendation algorithms to create a more comprehensive recommending system.
\subsection{Neural Collaborative Filtering}
NCF is a technique that uses neural networks to learn the customer's preferences and recommend items. It uses one neural network that learns the customer's preferences and another neural network that learns the item's features. The two networks are then combined to create a recommendation. As shown in Figure \ref{fig:neural-collaborative-filtering}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/neural-collaborative-filtering.png}
    \caption[Neural Collaborative Filtering]{Neural Collaborative Filtering~\cite{NvidiaRecSys}}
    \label{fig:neural-collaborative-filtering}
\end{figure}

\subsection{Contextual Sequence Learning}
Contextual Sequence Learning is a technique that takes into account the context and sequence of the user's action, it usually uses a RNN.
An example use case is session-based recommendations, RNNs predict the next items based on user event sequences, mirroring word embedding in NLP.
\subsection{Wide And Deep}
Wide \& Deep is a technique that uses a wide neural network to learn the preferences of the customer and utilizes another DNN to learn the products's features. The wide model is a GLM and the deep model is built from a dense neural Network. The two models are then combined to create a recommendation. As shown in Figure \ref{fig:wide-deep}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/wide_deep.png}
    \caption[Wide Deep Structure]{Wide Deep Structure~\cite{NvidiaRecSys}}
    \label{fig:wide-deep}
\end{figure}
\subsection{Deep and Cross Network-V2}
DCN-V2 builds on the DCN model to excel at ranking tasks. It tackles this by analyzing both direct connections between features and more complex interactions. Unlike DCN, it effectively captures these intricate relationships. Figure \ref{fig:deep-cross-network} shows the structure of the Deep Cross Network. This makes it especially good at understanding how individual features influence each other to impact the final ranking~\cite{DCNv2}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/dcn-v2.png}
    \caption[Deep Cross Network Structure]{Deep Cross Network Structure~\cite{DCNv2}}
    \label{fig:deep-cross-network}
\end{figure}

\subsection{Multi-layer perceptron}
MLP is a technique that uses a DNN to learn the customer's preferences and recommend items. It uses an embedding layer to learn the customer's preferences and another embedding layer to learn the item's features. The two embedding layers are then combined to create a recommendation. As shown in Figure \ref{fig:multi-layer-perceptron}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{assets/mlp.png}
    \caption[MLP Structure]{MLP Structure~\cite{ExploringMerlinModels}}
    \label{fig:multi-layer-perceptron}
\end{figure}

\subsection{DLRM}
DLRM is a technique that uses a DNN to handle categorical and numerical features. 
Each categorical feature is represented as a dense vector produced by an embedding model, 
and each numerical feature is represented as a dense vector, both fed into MLP layers. 
The output of the MLP layers is then fed into a dot product layer to compute the inner product of the feature vectors. 
Finally, the output of the dot product layer is then fed into a sigmoid layer to compute the probability of the user liking the item. Figure \ref{fig:dlrm} shows the structure of the DLRM model.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{assets/dlrm.png}
    \caption[DLRM Structure]{DLRM Structure~\cite{NvidiaRecSys}}
    \label{fig:dlrm}
\end{figure}
